A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first analyzes the medical image to provide the image plane, modality, title, and caption, then performs step-by-step reasoning that integrates both the visual evidence and the metadata above, and finally provides a concise answer derived from the reasoning process. The image plane, modality, title, caption, reasoning process, and answer are enclosed within <plane> </plane>, <modality> </modality>, <title> </title>, <caption> </caption>, <think> </think> and <answer> </answer> tags, respectively.

Expected format: <plane> image plane </plane><modality> image modality </modality><title> image title </title><caption> image caption describing the visual content, anatomical structures, abnormalities, or clinical findings visible in the image </caption><think> Provide: (1) Evidence — bullet-like sentences pointing to concrete image findings and metadata cues; (2) Interpretation — explain what each piece of evidence means clinically; (3) Conclusion — start with "Based on the evidence and interpretation above, the answer is:" and give a concise answer (typically a single word, phrase, or short medical term). The answer must be directly justified by the evidence and interpretation above, ensuring strict reasoning-answer alignment. </think><answer> copy the words following "Based on the evidence and interpretation above, the answer is:" verbatim, adding nothing else </answer>
