# CUDA_VISIBLE_DEVICES=0  NPROC_PER_NODE=1  MAX_PIXELS=602112  swift rlhf  --rlhf_type grpo  --train_type lora  --load_from_cache_file true  --torch_dtype bfloat16  --learning_rate 1e-6  --max_steps 100  --warmup_ratio 0.05  --logging_steps 5  --eval_steps 500  --save_steps 500  --save_total_limit 2  --output_dir output  --dataloader_num_workers 1  --attn_impl flash_attn  --use_vllm true  --vllm_mode colocate  --vllm_gpu_memory_utilization 0.55  --vllm_tensor_parallel_size 1  --vllm_max_model_len 2048  --max_length 2048  --max_completion_length 1024  --num_generations 4  --per_device_train_batch_size 1  --per_device_eval_batch_size 1  --gradient_accumulation_steps 4  --temperature 1.0  --top_p 1.0  --top_k 80  --deepspeed zero3_offload  --offload_optimizer true  --offload_model true  --log_completions true  --system examples/train/grpo/prompt.txt  --reward_funcs smart_accuracy format  --dataset AI-ModelScope/chartqa_digit_r1v_format  --model Qwen/Qwen3-VL-4B-Instruct
# CUDA_VISIBLE_DEVICES=0  NPROC_PER_NODE=1  MAX_PIXELS=602112  swift rlhf  --rlhf_type grpo  --train_type lora  --load_from_cache_file true  --torch_dtype bfloat16  --learning_rate 1e-6  --max_steps 100  --warmup_ratio 0.05  --logging_steps 5  --eval_steps 500  --save_steps 500  --save_total_limit 2  --output_dir output  --dataloader_num_workers 1  --attn_impl flash_attn  --use_vllm true  --vllm_mode colocate  --vllm_gpu_memory_utilization 0.55  --vllm_tensor_parallel_size 1  --vllm_max_model_len 2048  --max_length 2048  --max_completion_length 1024  --num_generations 4  --per_device_train_batch_size 1  --per_device_eval_batch_size 1  --gradient_accumulation_steps 4  --temperature 1.0  --top_p 1.0  --top_k 80  --deepspeed zero3_offload  --offload_optimizer true  --offload_model true  --log_completions true  --system examples/train/grpo/prompt.txt  --reward_funcs smart_accuracy format  --dataset AI-ModelScope/chartqa_digit_r1v_format  --model Qwen/Qwen3-VL-2B-Thinking
# CUDA_VISIBLE_DEVICES=0  NPROC_PER_NODE=1  MAX_PIXELS=602112  swift rlhf  --rlhf_type grpo  --train_type lora  --load_from_cache_file true  --torch_dtype bfloat16  --learning_rate 1e-6  --max_steps 100  --warmup_ratio 0.05  --logging_steps 5  --eval_steps 500  --save_steps 500  --save_total_limit 2  --output_dir output  --dataloader_num_workers 1  --attn_impl flash_attn  --use_vllm true  --vllm_mode colocate  --vllm_gpu_memory_utilization 0.55  --vllm_tensor_parallel_size 1  --vllm_max_model_len 2048  --max_length 2048  --max_completion_length 1024  --num_generations 4  --per_device_train_batch_size 1  --per_device_eval_batch_size 1  --gradient_accumulation_steps 4  --temperature 1.0  --top_p 1.0  --top_k 80  --deepspeed zero0  --offload_optimizer true  --offload_model true  --log_completions true  --system examples/train/grpo/prompt.txt  --reward_funcs smart_accuracy format  --dataset AI-ModelScope/chartqa_digit_r1v_format  --model BytedanceDouyinContent/SAIL-VL2-2B-Thinking
# CUDA_VISIBLE_DEVICES=0  NPROC_PER_NODE=1  MAX_PIXELS=602112  swift rlhf  --rlhf_type grpo  --train_type lora  --load_from_cache_file true  --torch_dtype bfloat16  --learning_rate 1e-6  --max_steps 100  --warmup_ratio 0.05  --logging_steps 5  --eval_steps 500  --save_steps 500  --save_total_limit 2  --output_dir output  --dataloader_num_workers 1  --attn_impl flash_attn  --use_vllm true  --vllm_mode colocate  --vllm_gpu_memory_utilization 0.55  --vllm_tensor_parallel_size 1  --vllm_max_model_len 2048  --max_length 2048  --max_completion_length 1024  --num_generations 4  --per_device_train_batch_size 1  --per_device_eval_batch_size 1  --gradient_accumulation_steps 4  --temperature 1.0  --top_p 1.0  --top_k 80  --deepspeed zero0  --offload_optimizer true  --offload_model true  --log_completions true  --system examples/train/grpo/prompt.txt  --reward_funcs smart_accuracy format  --dataset AI-ModelScope/chartqa_digit_r1v_format  --model LLM-Research/gemma-3-4b-it
# CUDA_VISIBLE_DEVICES=0  NPROC_PER_NODE=1  MAX_PIXELS=602112  swift rlhf  --rlhf_type grpo  --train_type lora  --load_from_cache_file true  --torch_dtype bfloat16  --learning_rate 1e-6  --max_steps 100  --warmup_ratio 0.05  --logging_steps 5  --eval_steps 500  --save_steps 500  --save_total_limit 2  --output_dir output  --dataloader_num_workers 1  --attn_impl flash_attn  --use_vllm true  --vllm_mode colocate  --vllm_gpu_memory_utilization 0.50  --vllm_tensor_parallel_size 1  --vllm_max_model_len 2048  --max_length 2048  --max_completion_length 1024  --num_generations 4  --per_device_train_batch_size 1  --per_device_eval_batch_size 1  --gradient_accumulation_steps 4  --temperature 1.0  --top_p 1.0  --top_k 80  --deepspeed zero0  --offload_optimizer true  --offload_model true  --log_completions true  --system examples/train/grpo/prompt.txt  --reward_funcs smart_accuracy format  --dataset AI-ModelScope/chartqa_digit_r1v_format  --model LLM-Research/Phi-3.5-vision-instruct
# CUDA_VISIBLE_DEVICES=0  NPROC_PER_NODE=1  MAX_PIXELS=602112  swift rlhf  --rlhf_type grpo  --train_type lora  --load_from_cache_file true  --torch_dtype bfloat16  --learning_rate 1e-6  --max_steps 100  --warmup_ratio 0.05  --logging_steps 5  --eval_steps 500  --save_steps 500  --save_total_limit 2  --output_dir output  --dataloader_num_workers 1  --attn_impl flash_attn  --use_vllm true  --vllm_mode colocate  --vllm_gpu_memory_utilization 0.55  --vllm_tensor_parallel_size 1  --vllm_max_model_len 2048  --max_length 2048  --max_completion_length 1024  --num_generations 4  --per_device_train_batch_size 1  --per_device_eval_batch_size 1  --gradient_accumulation_steps 4  --temperature 1.0  --top_p 1.0  --top_k 80  --deepspeed zero0  --offload_optimizer true  --offload_model true  --log_completions true  --system examples/train/grpo/prompt.txt  --reward_funcs accuracy format  --dataset ahmed-masry/ChartQAPro  --model LLM-Research/gemma-3-4b-it
# CUDA_VISIBLE_DEVICES=0  NPROC_PER_NODE=1  MAX_PIXELS=602112  swift rlhf  --rlhf_type grpo  --train_type lora  --load_from_cache_file true  --torch_dtype bfloat16  --learning_rate 1e-6  --max_steps 100  --warmup_ratio 0.05  --logging_steps 5  --eval_steps 500  --save_steps 500  --save_total_limit 2  --output_dir output  --dataloader_num_workers 1  --attn_impl flash_attn  --use_vllm true  --vllm_mode colocate  --vllm_gpu_memory_utilization 0.55  --vllm_tensor_parallel_size 1  --vllm_max_model_len 2048  --max_length 2048  --max_completion_length 1024  --num_generations 4  --per_device_train_batch_size 1  --per_device_eval_batch_size 1  --gradient_accumulation_steps 4  --temperature 1.0  --top_p 1.0  --top_k 80  --deepspeed zero0  --offload_optimizer true  --offload_model true  --log_completions true  --system examples/train/grpo/prompt.txt  --reward_funcs smart_accuracy format  --dataset /data/datasets/chart2code/json/chartrl.jsonl  --model Qwen/Qwen2.5-VL-3B-Instruct
# CUDA_VISIBLE_DEVICES=0 swift infer --val_dataset /data/datasets/slake/slake_test.jsonl --max_new_tokens 1024 --max_model_len 1024 --model Qwen/Qwen3-VL-32B-Thinking --quant_method bnb --quant_bits 4 --torch_dtype bfloat16 --stream true
# CUDA_VISIBLE_DEVICES=0 swift infer --val_dataset /data/datasets/slake/slake_test.jsonl#10 --max_new_tokens 1024 --max_model_len 1024 --quant_method bnb --quant_bits 4 --torch_dtype bfloat16 --stream true --model Qwen/Qwen3-VL-30B-A3B-Thinking
# CUDA_VISIBLE_DEVICES=0 swift infer --val_dataset /data/datasets/charxiv/charxiv_val.jsonl --max_new_tokens 1024 --max_model_len 1024 --quant_method bnb --quant_bits 4 --torch_dtype bfloat16 --stream true --model Qwen/Qwen3-VL-32B-Thinking
# CUDA_VISIBLE_DEVICES=0 swift infer --val_dataset /data/datasets/slake/slake_test.jsonl#10 --max_new_tokens 1024 --max_model_len 1024 --quant_method bnb --quant_bits 4 --torch_dtype bfloat16 --stream true --model Qwen/Qwen3-VL-32B-Instruct
# CUDA_VISIBLE_DEVICES=0 swift infer --val_dataset /data/datasets/charxiv/charxiv_val.jsonl --max_new_tokens 8192 --max_model_len 8192 --stream true --model Qwen/Qwen3-VL-4B-Instruct
# CUDA_VISIBLE_DEVICES=0 swift infer --val_dataset /data/datasets/vqarad/vqarad_test.jsonl --system "Answer the question concisely based on the image." --max_new_tokens 8192 --max_model_len 8192 --stream true --model Qwen/Qwen3-VL-2B-Instruct
# CUDA_VISIBLE_DEVICES=0 swift infer --val_dataset /data/datasets/vqarad/vqarad_test.jsonl --system "Answer the question concisely based on the image." --max_new_tokens 8192 --max_model_len 8192 --stream true --model Qwen/Qwen3-VL-4B-Instruct
# CUDA_VISIBLE_DEVICES=0 swift infer --val_dataset /data/datasets/vqarad/vqarad_test.jsonl --system "Answer the question concisely based on the image." --max_new_tokens 8192 --max_model_len 8192 --quant_method bnb --quant_bits 4 --torch_dtype bfloat16 --stream true --model Qwen/Qwen3-VL-32B-Instruct
# CUDA_VISIBLE_DEVICES=0  NPROC_PER_NODE=1  MAX_PIXELS=602112  swift rlhf  --rlhf_type grpo  --train_type lora  --load_from_cache_file true  --torch_dtype bfloat16  --learning_rate 1e-6  --max_steps 100  --warmup_ratio 0.05  --logging_steps 1  --eval_steps 500  --save_steps 500  --save_total_limit 2  --output_dir output  --dataloader_num_workers 1  --attn_impl flash_attn  --use_vllm true  --vllm_mode colocate  --vllm_gpu_memory_utilization 0.55  --vllm_tensor_parallel_size 1  --vllm_max_model_len 4096  --max_length 2048  --max_completion_length 2048  --num_generations 4  --per_device_train_batch_size 1  --per_device_eval_batch_size 1  --gradient_accumulation_steps 4  --temperature 1.0  --top_p 1.0  --top_k 80  --system examples/train/grpo/prompt.txt  --log_completions true  --offload_optimizer true  --offload_model true  --deepspeed zero3_offload  --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl  --reward_funcs smart_accuracy format  --model Qwen/Qwen3-VL-2B-Instruct
# CUDA_VISIBLE_DEVICES=0  NPROC_PER_NODE=1  MAX_PIXELS=602112  swift rlhf  --rlhf_type grpo  --train_type lora  --load_from_cache_file true  --torch_dtype bfloat16  --learning_rate 1e-6  --max_steps 100  --warmup_ratio 0.05  --logging_steps 1  --eval_steps 500  --save_steps 500  --save_total_limit 2  --output_dir output  --dataloader_num_workers 1  --attn_impl flash_attn  --use_vllm true  --vllm_mode colocate  --vllm_gpu_memory_utilization 0.55  --vllm_tensor_parallel_size 1  --vllm_max_model_len 4096  --max_length 2048  --max_completion_length 2048  --num_generations 4  --per_device_train_batch_size 1  --per_device_eval_batch_size 1  --gradient_accumulation_steps 4  --temperature 1.0  --top_p 1.0  --top_k 80  --system examples/train/grpo/prompt.txt  --log_completions true  --offload_optimizer true  --offload_model true  --deepspeed zero3_offload  --reward_funcs smart_accuracy format  --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl  --model Qwen/Qwen3-VL-2B-Instruct
# CUDA_VISIBLE_DEVICES=0  NPROC_PER_NODE=1  MAX_PIXELS=602112  swift rlhf  --rlhf_type grpo  --train_type lora  --load_from_cache_file true  --torch_dtype bfloat16  --learning_rate 1e-6  --max_steps 100  --warmup_ratio 0.05  --logging_steps 1  --eval_steps 500  --save_steps 500  --save_total_limit 2  --output_dir output  --dataloader_num_workers 1  --attn_impl flash_attn  --use_vllm true  --vllm_mode colocate  --vllm_gpu_memory_utilization 0.55  --vllm_tensor_parallel_size 1  --vllm_max_model_len 2048  --max_length 1024  --max_completion_length 1024  --num_generations 4  --per_device_train_batch_size 1  --per_device_eval_batch_size 1  --gradient_accumulation_steps 4  --temperature 1.0  --top_p 1.0  --top_k 80  --system examples/train/grpo/prompt.txt  --log_completions true  --offload_optimizer true  --offload_model true  --deepspeed zero0  --reward_funcs smart_accuracy format  --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl  --model LLM-Research/gemma-3-4b-it
# CUDA_VISIBLE_DEVICES=0  NPROC_PER_NODE=1  MAX_PIXELS=602112  swift rlhf  --rlhf_type grpo  --train_type lora  --load_from_cache_file true  --torch_dtype bfloat16  --learning_rate 1e-6  --max_steps 5000  --warmup_ratio 0.05  --logging_steps 1  --eval_steps 500  --save_steps 500  --save_total_limit 2  --output_dir output  --dataloader_num_workers 1  --attn_impl flash_attn  --use_vllm true  --vllm_mode colocate  --vllm_gpu_memory_utilization 0.55  --vllm_tensor_parallel_size 1  --vllm_max_model_len 2048  --max_length 1024  --max_completion_length 1024  --num_generations 4  --per_device_train_batch_size 1  --per_device_eval_batch_size 1  --gradient_accumulation_steps 4  --temperature 1.0  --top_p 1.0  --top_k 80  --system examples/train/grpo/prompt.txt  --log_completions true  --offload_optimizer true  --offload_model true  --deepspeed zero0  --reward_funcs smart_accuracy format  --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl  --model Qwen/Qwen2.5-VL-3B-Instruct
# CUDA_VISIBLE_DEVICES=0 swift infer --val_dataset /data/datasets/vqarad/vqarad_test.jsonl --system examples/train/grpo/prompt.txt --max_new_tokens 2048 --max_model_len 2048 --stream true --adapters /data/workspace/swift/output/v54-20251117-030137/checkpoint-500
# CUDA_VISIBLE_DEVICES=0 swift infer --val_dataset /data/datasets/vqarad/vqarad_test.jsonl --system "Answer the question concisely based on the image." --max_new_tokens 2048 --max_model_len 2048 --stream true --model Qwen/Qwen2.5-VL-3B-Instruct
# CUDA_VISIBLE_DEVICES=0  NPROC_PER_NODE=1  MAX_PIXELS=602112  swift rlhf  --rlhf_type grpo  --train_type lora  --load_from_cache_file true  --torch_dtype bfloat16  --learning_rate 5e-6  --max_steps 10000  --warmup_ratio 0.05  --logging_steps 10  --eval_steps 1000  --save_steps 1000  --save_total_limit 10  --output_dir output  --dataloader_num_workers 1  --attn_impl flash_attn  --use_vllm true  --vllm_mode colocate  --vllm_gpu_memory_utilization 0.55  --vllm_tensor_parallel_size 1  --vllm_max_model_len 2048  --max_length 2048  --max_completion_length 1024  --num_generations 4  --per_device_train_batch_size 1  --per_device_eval_batch_size 1  --gradient_accumulation_steps 4  --temperature 0.9  --top_p 0.9  --top_k 100  --system examples/train/grpo/prompt.txt  --log_completions true  --offload_optimizer true  --offload_model true  --deepspeed zero0  --reward_funcs answer_match_string plane_match_string modality_match_string caption_match_cosine format  --reward_weights 0.60 0.10 0.10 0.10 0.10  --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl  --model Qwen/Qwen2.5-VL-3B-Instruct  --report_to wandb  
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 1e-5 --lr_scheduler_type cosine --max_steps 10000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 10 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.55 --vllm_tensor_parallel_size 1 --vllm_max_model_len 2048 --max_length 1024 --max_completion_length 1024 --num_generations 4 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 4 --temperature 0.8 --top_p 0.9 --top_k 100 --system examples/train/grpo/prompt.txt --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs format answer_match_string plane_match_string modality_match_string caption_match_cosine --reward_weights 0.20 0.40 0.15 0.15 0.10 --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen2.5-VL-3B-Instruct --report_to wandb
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 1e-5 --lr_scheduler_type cosine --max_steps 5000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 10 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.55 --vllm_tensor_parallel_size 1 --vllm_max_model_len 2048 --max_length 1024 --max_completion_length 1024 --num_generations 8 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 8 --temperature 0.8 --top_p 0.9 --top_k 100 --system examples/train/grpo/prompt.txt --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs format answer_match_cosine plane_match_string modality_match_string caption_match_cosine --reward_weights 0.05 0.50 0.05 0.05 0.35 --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen2.5-VL-3B-Instruct --report_to wandb
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 1e-5 --lr_scheduler_type cosine --max_steps 10000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 10 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.50 --vllm_tensor_parallel_size 1 --vllm_max_model_len 2048 --max_length 1024 --max_completion_length 1024 --num_generations 4 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 4 --temperature 0.8 --top_p 0.9 --top_k 100 --system examples/train/grpo/prompt.txt --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs format answer_match_cosine plane_match_string modality_match_string caption_match_cosine --reward_weights 0.05 0.45 0.05 0.05 0.40 --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen2.5-VL-3B-Instruct --report_to wandb
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 5e-6 --lr_scheduler_type cosine --max_steps 5000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 10 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.50 --vllm_tensor_parallel_size 1 --vllm_max_model_len 4096 --max_length 1024 --max_completion_length 1024 --num_generations 8 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 8 --temperature 1.0 --top_p 0.9 --top_k 80 --system examples/train/grpo/prompt.txt --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs answer_match_cosine title_match_cosine caption_match_cosine plane_match_string modality_match_string format --reward_weights 1.0 0.5 0.5 0.1 0.1 0.5 --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen3-VL-2B-Thinking --report_to wandb
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 5e-6 --lr_scheduler_type cosine --max_steps 5000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 10 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.50 --vllm_tensor_parallel_size 1 --vllm_max_model_len 4096 --max_length 1024 --max_completion_length 1024 --num_generations 8 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 8 --temperature 1.0 --top_p 0.9 --top_k 80 --system examples/train/grpo/prompt.txt --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs answer_match_cosine title_match_cosine caption_match_cosine plane_match_string modality_match_string format --reward_weights 1.0 0.5 0.5 0.1 0.1 0.5 --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen3-VL-2B-Instruct --report_to wandb
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 1e-4 --lr_scheduler_type cosine --max_steps 5000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 10 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.50 --vllm_tensor_parallel_size 1 --vllm_max_model_len 4096 --max_length 1024 --max_completion_length 1024 --num_generations 8 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 8 --temperature 1.0 --top_p 0.9 --top_k 80 --system examples/train/grpo/prompt.txt --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs answer_match_cosine title_match_cosine caption_match_cosine plane_match_string modality_match_string format --reward_weights 1.5 0.5 0.5 0.1 0.1 0.5 --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen3-VL-2B-Instruct --report_to wandb
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 1e-4 --lr_scheduler_type cosine --max_steps 5000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 10 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.55 --vllm_tensor_parallel_size 1 --vllm_max_model_len 2048 --max_length 1024 --max_completion_length 1024 --num_generations 8 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 8 --temperature 1.0 --top_p 0.9 --top_k 80 --system examples/train/grpo/prompt.txt --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs answer_match_cosine title_match_cosine caption_match_cosine plane_match_string modality_match_string format --reward_weights 1.5 0.5 0.5 0.1 0.1 0.5 --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model LLM-Research/gemma-3-4b-it --report_to wandb
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 1e-4 --lr_scheduler_type cosine --max_steps 5000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 10 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.50 --vllm_tensor_parallel_size 1 --vllm_max_model_len 4096 --max_length 1024 --max_completion_length 1024 --num_generations 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 16 --temperature 1.0 --top_p 0.9 --top_k 80 --system examples/train/grpo/prompt.txt --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs answer_match_cosine title_match_cosine caption_match_cosine plane_match_string modality_match_string format --reward_weights 1.5 0.5 0.5 0.1 0.1 0.5 --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen2.5-VL-3B-Instruct --report_to wandb
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 1e-4 --lr_scheduler_type cosine --max_steps 10000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 12 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.50 --vllm_tensor_parallel_size 1 --vllm_max_model_len 2048 --max_length 1024 --max_completion_length 512 --num_generations 32 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 32 --temperature 1.0 --top_p 0.9 --top_k 80 --system examples/train/grpo/prompt.txt --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs answer_match_cosine title_match_cosine caption_match_cosine plane_match_string modality_match_string format --reward_weights 2.0 0.5 0.5 0.1 0.1 0.1 --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen2.5-VL-3B-Instruct --report_to wandb
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 1e-4 --lr_scheduler_type cosine --max_steps 8000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 10 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.55 --vllm_tensor_parallel_size 1 --vllm_max_model_len 4096 --max_length 1024 --max_completion_length 1024 --num_generations 32 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 32 --temperature 1.0 --top_p 0.9 --top_k 80 --system examples/train/grpo/prompt.txt --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs answer_match_cosine title_match_cosine caption_match_cosine plane_match_string modality_match_string format --reward_weights 2.0 0.5 0.5 0.1 0.1 0.1 --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen2.5-VL-3B-Instruct --report_to wandb
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 1e-4 --lr_scheduler_type cosine --max_steps 8000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 10 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.50 --vllm_tensor_parallel_size 1 --vllm_max_model_len 4096 --max_length 1024 --max_completion_length 1024 --num_generations 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 16 --temperature 1.0 --top_p 0.9 --top_k 80 --system examples/train/grpo/prompt.txt --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs answer_match_cosine title_match_cosine caption_match_cosine plane_match_string modality_match_string format --reward_weights 2.0 0.5 0.5 0.1 0.1 0.1 --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen2.5-VL-3B-Instruct --report_to wandb
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 1e-5 --lr_scheduler_type cosine --max_steps 6000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 5 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.50 --vllm_tensor_parallel_size 1 --vllm_max_model_len 4096 --max_length 1024 --max_completion_length 512 --num_generations 8 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 8 --temperature 1.0 --top_p 0.9 --top_k 80 --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs answer_match_cosine caption_match_cosine title_match_cosine plane_match_string modality_match_string format --reward_weights 1.0 1.0 0.5 0.1 0.1 0.1 --system /data/workspace/swift/prompt3.txt --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen2.5-VL-3B-Instruct --report_to wandb
# CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 1e-5 --lr_scheduler_type cosine --max_steps 6000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 5 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.50 --vllm_tensor_parallel_size 1 --vllm_max_model_len 4096 --max_length 1024 --max_completion_length 512 --num_generations 8 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 8 --temperature 1.0 --top_p 0.9 --top_k 80 --log_completions true --offload_optimizer true --offload_model true --deepspeed zero0 --reward_funcs answer_match_cosine caption_match_cosine title_match_cosine plane_match_string modality_match_string format --reward_weights 1.0 1.0 0.5 0.1 0.1 0.5 --system /data/workspace/swift/prompt3.txt --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen2.5-VL-3B-Instruct --report_to wandb --resume_from_checkpoint /data/workspace/swift/output/v99-20251124-233227/checkpoint-1000
CUDA_VISIBLE_DEVICES=0 NPROC_PER_NODE=1 MAX_PIXELS=602112 swift rlhf --rlhf_type grpo --train_type lora --load_from_cache_file true --torch_dtype bfloat16 --learning_rate 5e-5 --lr_scheduler_type cosine --max_steps 6000 --warmup_ratio 0.05 --logging_steps 5 --eval_steps 500 --save_steps 500 --save_total_limit 5 --output_dir output --dataloader_num_workers 1 --attn_impl flash_attn --use_vllm true --vllm_mode colocate --vllm_gpu_memory_utilization 0.50 --vllm_tensor_parallel_size 1 --vllm_max_model_len 2048 --max_length 1024 --max_completion_length 512 --num_generations 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 16 --temperature 1.0 --top_p 0.9 --top_k 80 --log_completions true --offload_optimizer true --offload_model true --deepspeed zero3 --reward_funcs answer_match_cosine caption_match_cosine title_match_cosine plane_match_string modality_match_string format --reward_weights 2.0 1.0 0.5 0.1 0.1 0.5 --system /data/workspace/swift/prompt4.txt --dataset /data/datasets/vqarad/vqarad_train_rl.jsonl --model Qwen/Qwen2.5-VL-3B-Instruct --report_to wandb



